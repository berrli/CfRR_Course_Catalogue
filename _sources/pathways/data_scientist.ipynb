{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d57c069",
   "metadata": {},
   "source": [
    "# Python: Scikit-Learn "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd96d11",
   "metadata": {},
   "source": [
    "## Course Skip Quiz\n",
    "\n",
    "The following questions are aimed at testing your understanding of the content that is covered within this course. There is no defined threshold where we believe you should attend the course if you score below. Rather it is aimed to make you engage with the content and reflect for yourself if you feel you would benefit from attending the course. Of note, is that the quiz is intended for you to use google throuhgout and engage with documentation. Even if you get all of the questions right, you are ofcourse more than welcome to still attend the course and use it as a refresher!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef84246",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyterquiz import display_quiz\n",
    "display_quiz(\"../questions/course_skip_quizes/scikitlearn_course_skip_quiz.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1029991b",
   "metadata": {},
   "source": [
    "## Course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee4f73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the packages used before and read in the required data\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "air_pollution_data_2023_complete_dataset = pd.read_csv(\"../data/LEED_air_pollution_monitoring_station_2023_complete_dataset.csv\", index_col=0)\n",
    "air_pollution_data_2023_complete_dataset = air_pollution_data_2023_complete_dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039d398e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit learn can be imported with the the following command\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc01645",
   "metadata": {},
   "source": [
    "## What is Scikit-Learn?\n",
    "\n",
    "Scikit-Learn is a popular Python package that provides a set of algorithms and tools for machine learning that are both easy to use and effective. The package includes support for various tasks, including classification, regression, clustering, dimensionality reduction and model selection and normalization.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4c4625",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_pollution_data_2023_complete_dataset[\"date\"] = pd.to_datetime(air_pollution_data_2023_complete_dataset[\"date\"], format=\"%d/%m/%Y %H:%M\")\n",
    "air_pollution_data_2023_complete_dataset[\"Hour\"] = air_pollution_data_2023_complete_dataset[\"date\"].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd6562b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(air_pollution_data_2023_complete_dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba1ec53",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Linear Regression\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# Create some simple data\n",
    "X = air_pollution_data_2023_complete_dataset[[\"Wind Speed\"]]\n",
    "y = air_pollution_data_2023_complete_dataset[[\"NO2\"]]\n",
    "\n",
    "# Train a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Plotting the data points\n",
    "plt.scatter(X, y, color='blue', label='Observations', alpha=0.05)\n",
    "\n",
    "# Predicting the values to draw the regression line\n",
    "# We use minimum and maximum values of X to cover the whole range of data\n",
    "X_new = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)  # Making it a column vector\n",
    "y_predict = model.predict(X_new)\n",
    "\n",
    "# Plotting the regression line\n",
    "plt.plot(X_new, y_predict, color='red', linewidth=2, label='Regression Line')\n",
    "\n",
    "# Adding title and labels\n",
    "plt.title('Relationship Between Wind Speed and NO$_2$ Levels')\n",
    "plt.xlabel('Wind Speed m/s')\n",
    "plt.ylabel('NO$_2$ Concentration')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Extracting and printing the intercept and slope\n",
    "intercept = model.intercept_\n",
    "slope = model.coef_\n",
    "\n",
    "print(\"Intercept of the regression line:\", intercept[0])  # Intercept is usually an array with a single element\n",
    "print(\"Slope of the regression line:\", slope[0][0])  # Slope is an array of arrays, each containing one element per feature\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac996311",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyterquiz import display_quiz\n",
    "display_quiz(\"../questions/scikitlearn_question_linear_regression_question.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcc2710",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Set the number of clusters\n",
    "k = 3  # Example number of clusters\n",
    "\n",
    "# Create KMeans model\n",
    "kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "\n",
    "# Fit the model\n",
    "clusters = kmeans.fit_predict(air_pollution_data_2023_complete_dataset[['NO2', 'Temperature']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1c847d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the cluster information to the DataFrame\n",
    "air_pollution_data_2023_complete_dataset['cluster'] = clusters\n",
    "\n",
    "# Plotting clusters\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(air_pollution_data_2023_complete_dataset['NO2'], air_pollution_data_2023_complete_dataset['Wind Speed'], c=air_pollution_data_2023_complete_dataset['cluster'], cmap='viridis', alpha=0.15)\n",
    "plt.title('Clusters of Air Pollution Data')\n",
    "plt.xlabel('NO2 Concentration')\n",
    "plt.ylabel('Wind Speed')\n",
    "plt.colorbar(scatter)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cfdb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Models \n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Initialize the model\n",
    "decision_tree_regressor = DecisionTreeRegressor(random_state=42, max_depth=2)\n",
    "\n",
    "# Train the model on the entire dataset\n",
    "decision_tree_regressor.fit(air_pollution_data_2023_complete_dataset[[\"Wind Speed\"]], air_pollution_data_2023_complete_dataset[\"NO2\"])\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# Plot the decision tree\n",
    "plt.figure(figsize=(50,10))\n",
    "plot_tree(decision_tree_regressor, feature_names=['Wind Speed'], filled=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195ab4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_quiz(\"../questions/sciktilearn_question_decision_tree.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2307966d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "711449b1",
   "metadata": {},
   "source": [
    "## Decomposition\n",
    "\n",
    "Decomposition refers to the process of breaking down a complex problem into smaller, simpler sub-problems. The idea is to solve each subproblem independently \n",
    "and then combine the solutions to obtain a solution to the original problem. This allows for the creation of more efficient and manageable algorithm by \n",
    "reducing the complexity of the problem and making it easier to identify and solve individual parts. Equally, this makes your code more reusable as each function \n",
    "solves a smaller issue which may be reusable elsewhere. \n",
    "\n",
    "When breaking the problem down it can be helpful to first of all identify the \n",
    "* starting point\n",
    "    * what input do you have\n",
    "    * what are the initial conditions\n",
    "* end point. \n",
    "    * what output would you ultimately want\n",
    "    * what is the end goal \n",
    "\n",
    "You can then start to fill in the gaps in between. Through the process of building your algorithm you may find that your start point isn't actually the start point, you need to go further back in the process. Similarly you might find your end goal needs to be redefined.\n",
    "\n",
    "For example in our tube navigation example crucially we are starting at Paddington TUBE Station, but our passenger is at Paddington RAIL station. Our algorithm is meaningless is they can't get to the TUBE station, so we need to add an additional step to navigate from the TRAIN station to the TUBE station. It is important to remember, that your computer knows absolutely nothing at the beginning of a new program you need to tell it everything. \n",
    "\n",
    "![toEdgware](../individual_modules/computational_thinking/images/directions.jpg)\n",
    "\n",
    "### Activity: Caesar cypher \n",
    "\n",
    "In cryptography, a Caesar cipher is a very simple encryption technique in which each letter in the plain text is replaced by a letter some fixed number of positions down the alphabet. For example, with a shift of 3, A would be replaced by D, B would become E, and so on. The method is named after Julius Caesar, who used it to communicate with his generals. ROT-13 (\"rotate by 13 places\") is a widely used example of a Caesar cipher where the shift is 13. \n",
    "\n",
    "Your task in this exercise is to design the algorithm that a computer would need to follow to encode/decode a message using ROT-13.  How does the idea of decomposition apply here? What would you do to implement this? \n",
    "\n",
    "It might be helpful to think through how you would manually decode the following message:\n",
    "\n",
    "```\n",
    "Pnrfne pvcure? V zhpu cersre Pnrfne fnynq!\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "Credits: [Torbjorn Lager](https://www.gu.se/en/about/find-staff/torbjornlager)\n",
    "\n",
    "Note: Because there are 26 letters (2×13) in the basic Latin alphabet, ROT13 is its own inverse; that is, to undo ROT13, the same algorithm is applied, so the same action can be used for encoding and decoding.\n",
    "\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
